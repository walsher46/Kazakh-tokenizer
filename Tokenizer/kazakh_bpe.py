# -*- coding: utf-8 -*-
"""KAZAKH_BPE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SBSB3pQ3HddSgaHQ_QONNLA9KiZTsJS5
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount("/content/drive", force_remount=True)

curr_dir = "/content/drive/MyDrive/SEGMENTATION_QAZ/segmented_kaz_285_only"
# %cd "$curr_dir"

import sentencepiece as spm
import glob

# Путь к чанкам (например, все файлы начинаются с chunk_)
chunk_files = sorted(glob.glob("chunk_***.txt"))

# Имя итогового файла
output_file = "kazakh_segmented_corpus_285.txt"

# Объединение файлов
with open(output_file, "w", encoding="utf-8") as outfile:
    for fname in chunk_files:
        with open(fname, "r", encoding="utf-8") as infile:
            for line in infile:
                outfile.write(line)

print(f"✅ Объединено {len(chunk_files)} файлов в {output_file}")



# Пути к файлам
input_file = "kazakh_segmented_corpus_285.txt"
model_prefix = "kazakh_bpe"
vocab_size = 50000  # можно уменьшить до 16000

# Запуск тренировки
try:
    spm.SentencePieceTrainer.Train(
        input=input_file,
        model_prefix=model_prefix,
        vocab_size=vocab_size,
        model_type="bpe",  # или "unigram"
        character_coverage=1.0,
        pad_id=0,
        unk_id=1,
        bos_id=2,
        eos_id=3,
        input_sentence_size=1000000,
        shuffle_input_sentence=True
    )
    print("✅ SentencePiece модель обучена!")
except Exception as e:
    print("❌ Произошла ошибка при обучении SentencePiece:")
    print(e)

print("✅ SentencePiece модель обучена!")

